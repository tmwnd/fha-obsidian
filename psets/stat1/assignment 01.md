1. Seien $X_j : (\Omega, \mathfrak{A}) \to (R, \mathfrak{S})$, $j = 1, \dots, n$, unter jedem $P_\vartheta \in \mathfrak{P}$ unabhängig und identisch verteilte Zufallsvariablen, deren zugrunde liegende Verteilung, die in der Vorlesung genannten Voraussetzungen zur Definition der Informationsmatrix $X_{X_1}(\vartheta)$ aus $X = (X_1, \dots, X_n)$ int $\vartheta \in \Theta$.

^1

2. Es sei $f : \mathbb{R} \to (0, \infty)$ eine stetig differenzierbare Dichte.
	Die reelle Zufallsvariable $X$ habe die Dichte $f(x - \theta)$, $x \in \mathbb{R}$, wobei $\theta \in \mathbb{R}$ unbekannt sei.
	
	1. Zeigen Sie, dass für die Information $i_X(\theta)$ aus $X$ über $\theta$ dann $i_X(\theta) = i_X(0)$ für alle $\theta \in \mathbb{R}$ gilt.
	2. Berechnen Sie $i_X(\theta)$ für den Fall, dass
		1. $f(x) = \frac{1}{\sqrt{2\pi}} e^{-\frac{1}{2} x^2}$, $x \in \mathbb{R}$, gilt,
		2. $f(x) = e^{-x}(1 + e^{-x})^{-2}$, $x \in \mathbb{R}$, gilt.

^2

3. Es sei $X = (X_1, \dots, X_n)$ mit unabhängige Zufallsvariablen $X_1, \dots, X_n$, je mit derselben $\mathfrak{P}(\lambda)$-Verteilung, wobei $\lambda \gt 0$ unbekannt ist.
	Zeigen Sie mittels der Kovarianzmethode von Rao, dass $\overline{X} = \frac{1}{2} \sum_{i=1}^n X_i$ ein gleichmäßig bester erwartungstreuer Schätzer für $\lambda$ ist.

^3